{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 양방향 LSTM 감성 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서 *양방향* LSTM을 만들어 감성에 따라 IMDB 영화 리뷰를 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/dl-illustrated/blob/master/notebooks/11-6.bi_lstm_sentiment_classifier.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라이브러리 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional # new! \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 디렉토리\n",
    "output_dir = 'model_output/biLSTM'\n",
    "\n",
    "# 훈련\n",
    "epochs = 6\n",
    "batch_size = 128\n",
    "\n",
    "# 벡터 공간 임베딩\n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 200 # 두베!\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# LSTM 층 구조\n",
    "n_lstm = 256 \n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # n_words_to_skip 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               657408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,297,921\n",
      "Trainable params: 1,297,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 양 방향으로 가중치가 있기 때문에 LSTM 층 파라미터가 두 배가 됩니다.\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "196/196 [==============================] - 18s 92ms/step - loss: 0.5312 - accuracy: 0.7172 - val_loss: 0.3927 - val_accuracy: 0.8286\n",
      "Epoch 2/6\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.3106 - accuracy: 0.8761 - val_loss: 0.3311 - val_accuracy: 0.8611\n",
      "Epoch 3/6\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.2396 - accuracy: 0.9084 - val_loss: 0.3162 - val_accuracy: 0.8672\n",
      "Epoch 4/6\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.1973 - accuracy: 0.9268 - val_loss: 0.3273 - val_accuracy: 0.8686\n",
      "Epoch 5/6\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.1581 - accuracy: 0.9429 - val_loss: 0.3395 - val_accuracy: 0.8593\n",
      "Epoch 6/6\n",
      "196/196 [==============================] - 17s 86ms/step - loss: 0.1289 - accuracy: 0.9566 - val_loss: 0.3751 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e8bf014e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋이 작기 때문에 긴 문장에 걸쳐 단어의 복잡한 상호작용이 잘 학습되지 않습니다.\n",
    "# CNN은 리뷰의 감성을 예측하는 위치에 상관없는 2개에서 4개까지 단어 조각을 선택합니다.\n",
    "# 이 작업이 더 간단하기 때문에 데이터에서 학습하기 쉽습니다.\n",
    "# 따라서 CNN이 IMDB 데이터셋에서 성능이 더 좋습니다.\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.04.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93.96'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.3 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
