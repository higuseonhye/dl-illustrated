{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 감성 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서 LSTM을 사용해 감성에 따라 IMDB 영화 리뷰를 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/dl-illustrated/blob/master/notebooks/11-5.lstm_sentiment_classifier.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라이브러리 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM # new! \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 디렉토리\n",
    "output_dir = 'model_output/LSTM'\n",
    "\n",
    "# 훈련\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# 벡터 공간 임베딩\n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 100 \n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# LSTM 층 구조\n",
    "n_lstm = 256 \n",
    "drop_lstm = 0.2\n",
    "\n",
    "# 밀집 층 구조\n",
    "# n_dense = 256\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # n_words_to_skip 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(LSTM(n_lstm, dropout=drop_lstm))\n",
    "# model.add(Dense(n_dense, activation='relu')) \n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               328704    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 968,961\n",
      "Trainable params: 968,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.4942 - accuracy: 0.7496 - val_loss: 0.3635 - val_accuracy: 0.8394\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 6s 33ms/step - loss: 0.2951 - accuracy: 0.8802 - val_loss: 0.3701 - val_accuracy: 0.8477\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.2357 - accuracy: 0.9071 - val_loss: 0.4247 - val_accuracy: 0.8374\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.2000 - accuracy: 0.9240 - val_loss: 0.4021 - val_accuracy: 0.8425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70cc9e1550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.02.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.74'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.3 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
