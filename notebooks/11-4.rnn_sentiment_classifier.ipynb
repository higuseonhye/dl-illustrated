{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 감성 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서 RNN을 사용해 감성에 따라 IMDB 영화 리뷰를 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/dl-illustrated/blob/master/notebooks/11-4.rnn_sentiment_classifier.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라이브러리를 적재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import SimpleRNN # new! \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 디렉토리\n",
    "output_dir = 'model_output/rnn'\n",
    "\n",
    "# 훈련\n",
    "epochs = 16 # 더 많이!\n",
    "batch_size = 128\n",
    "\n",
    "# 벡터 공간 임베딩\n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 100 # 시간에 따른 그레이디언트 소실 때문에 낮춤\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# RNN 층 구조\n",
    "n_rnn = 256 \n",
    "drop_rnn = 0.2\n",
    "\n",
    "# 밀집 층 구조\n",
    "# n_dense = 256\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터를 적재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # n_words_to_skip 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터를 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
    "# model.add(Dense(n_dense, activation='relu')) # 일반적으로 NLP에서는 밀집 층을 위에 놓지 않습니다.\n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 256)               82176     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 722,433\n",
      "Trainable params: 722,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "196/196 [==============================] - 24s 124ms/step - loss: 0.6841 - accuracy: 0.5368 - val_loss: 0.6627 - val_accuracy: 0.5728\n",
      "Epoch 2/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.6701 - accuracy: 0.5820 - val_loss: 0.7307 - val_accuracy: 0.5123\n",
      "Epoch 3/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.6453 - accuracy: 0.6187 - val_loss: 0.6526 - val_accuracy: 0.5967\n",
      "Epoch 4/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.5433 - accuracy: 0.7246 - val_loss: 0.5410 - val_accuracy: 0.7264\n",
      "Epoch 5/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.4872 - accuracy: 0.7672 - val_loss: 0.5683 - val_accuracy: 0.6969\n",
      "Epoch 6/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.4092 - accuracy: 0.8212 - val_loss: 0.4619 - val_accuracy: 0.7982\n",
      "Epoch 7/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.3355 - accuracy: 0.8614 - val_loss: 0.4392 - val_accuracy: 0.8190\n",
      "Epoch 8/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.3549 - accuracy: 0.8494 - val_loss: 0.4776 - val_accuracy: 0.7957\n",
      "Epoch 9/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.3809 - accuracy: 0.8301 - val_loss: 0.5573 - val_accuracy: 0.7254\n",
      "Epoch 10/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.4376 - accuracy: 0.7958 - val_loss: 0.5487 - val_accuracy: 0.7699\n",
      "Epoch 11/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.3608 - accuracy: 0.8514 - val_loss: 0.5040 - val_accuracy: 0.7764\n",
      "Epoch 12/16\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.3259 - accuracy: 0.8685 - val_loss: 0.5442 - val_accuracy: 0.7465\n",
      "Epoch 13/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.3164 - accuracy: 0.8686 - val_loss: 0.6203 - val_accuracy: 0.6665\n",
      "Epoch 14/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.2893 - accuracy: 0.8864 - val_loss: 0.5371 - val_accuracy: 0.7871\n",
      "Epoch 15/16\n",
      "196/196 [==============================] - 24s 122ms/step - loss: 0.3615 - accuracy: 0.8421 - val_loss: 0.5822 - val_accuracy: 0.7831\n",
      "Epoch 16/16\n",
      "196/196 [==============================] - 24s 121ms/step - loss: 0.4396 - accuracy: 0.7900 - val_loss: 0.5429 - val_accuracy: 0.7418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dc2e71f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.07.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89.58'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.3 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
