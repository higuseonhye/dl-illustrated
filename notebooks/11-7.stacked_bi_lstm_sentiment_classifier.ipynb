{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 적층 양방향 LSTM 감성 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서 *적층* 양방향 LSTM을 사용해 감성에 따라 IMDB 영화 리뷰를 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/dl-illustrated/blob/master/notebooks/11-7.stacked_bi_lstm_sentiment_classifier.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라이브러리 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 디렉토리\n",
    "output_dir = 'model_output/stackedLSTM'\n",
    "\n",
    "# 훈련\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# 벡터 공간 임베딩\n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 200 \n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# LSTM 층 구조\n",
    "n_lstm_1 = 64 # 줄임\n",
    "n_lstm_2 = 64 # new!\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # n_words_to_skip 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm_1, dropout=drop_lstm, \n",
    "                             return_sequences=True))) \n",
    "model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 804,993\n",
      "Trainable params: 804,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 양 방향으로 역전파되기 때문에 LSTM 층의 파라미터가 두 배가 됩니다.\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.4212 - accuracy: 0.7894 - val_loss: 0.4699 - val_accuracy: 0.8077\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 0.2431 - accuracy: 0.9053 - val_loss: 0.3141 - val_accuracy: 0.8704\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 0.1841 - accuracy: 0.9304 - val_loss: 0.3448 - val_accuracy: 0.8546\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 0.1403 - accuracy: 0.9486 - val_loss: 0.3754 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9d92bb9ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.02.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.58'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.3 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
